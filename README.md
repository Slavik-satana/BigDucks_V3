# Emotion Classification
Решение от команды 40 (БигДаки) для хакатона MFTIDS_2 x URFUML

## Содержание

1. [Состав команды и роли](#состав-команды-и-роли)
2. [Актуальное состояние проекта](#актуальное-состояние-проекта)
3. [Используемые методы](#используемые-методы)
    * [Предобработка данных](#предобработка-данных)
    * [Архитектура модели](#архитектура-модели)
4. [Планы доработки](#планы-доработки)
5. [Структура Проекта](#структура-проекта)
6. [Установка](#установка)
7. [Запуск](#запуск)
8. [Результаты](#результаты)

## Состав команды и роли

- Самаковский Вячеслав: Тим-лид, расширение датасета
- Казиев Владислав: Построение классификатора, расширение датасета
- Гришин Егор: Построение классификатора, расширение датасета
- Алексеев Арслан: Расширение датасета, визуализация результатов

## Актуальное состояние проекта
В настоящий момент удалось набрать score `0.61930` на лидерборде в kaggle (2 место)

- Протестированные модели:
  - **ru-en-RoSBERTa** (В настоящий момент показала лучший результат)
  - xlm-roberta-base
  - rugpt3small_based_on_gpt2
  - ruRoberta-large
  - ru-t5-large

## Используемые методы

### Предобработка данных

- На данном этапе предобработка данных включает базовые шаги [пердобработки](#предобработка-и-постобработка).

Планируем исследовать влияние очистка данных и исправления ошибок с помощью `ai-forever/sage`.

## Архитектура модели


### Предобученная языковая модель (Transformer Encoder):
В качестве основы берем предобученную модель `ru-en-RoSBERTa`. Модель преобразует входной текст в эмбединг. Используем стандартная токенизация и механизм внимания.

### Классификация:
Задача решается как Multilabel классификация.
Лосс-функция — `BCEWithLogitsLoss`, которая хорошо подходит для Multilabel задач.

### Подбор порога:
Мы перебираем серию порогов для максимизации F1, что повышает качество распознавания.

### Предобработка и постобработка:
- Предварительная очистка текста от `неалфавитных символов` и `лишних пробелов`.
- Токенизация до фиксированной длины (padding/truncation).
- Кодирование в one-hot формат.
- Получив предсказания на `valid` и `test` — примененяем `оптимальный Threshold` для улучшения качества.

## Планы доработки

В ближайших планах команды:

1. Проверка влияния Stratified K Fold Cross Validation:
   - Для повышения стабильности и обобщающей способности модели.
   - Проверили. Не дало положительного результата.

2. Тестирование различных моделей из лидерборда на русском языке:
   - Исследование моделей [лидерборда HuggingFace](https://huggingface.co/spaces/mteb/leaderboard) на предмет их эффективности для нашей задачи.
   - Проверили. Лучшая модель по нашему тестированию `ai-forever/ru-en-RoSBERTa`.

3. Дальнейшее расширение датасета:
   - За счёт интеграции других релевантных датасетов, например, [ru-go-emotions](https://huggingface.co/datasets/seara/ru_go_emotions).
   - Проверили. Были расширены **все** классы кроме `joy` и `neutral`, удалены дубликаты (см. `extend_dataset.ipynb`).

4. Оптимизация предобработки данных:
   - Внедрение методов очистки данных от шума и ошибок для улучшения качества обучения.
   - Проверили. В итоге наилучшим методом оказалось простая очистка данных(убрать лишние пробелы, символы и т.д)


## Структура Проекта
### Новая:
- `data/`: Исходные данные. Включая расширение датасета `train_extended.csv`
- `cryptonite.ipynb`: Основной код обучения
- `extend_dataset.ipynb`: Код расширения датасета
- `outputs/`: Результаты работы, включая сабмишны
- `requirements.txt`: Зависимости проекта.
- `README.md`: Описание проекта.

### Старая:
- `data/`: Исходные данные.
- `src/`: Исходный код. (Старый код, теперь весь код в `.ipynb` см. выше)
- `outputs/`: Результаты работы, включая сабмишны и логи.
- `requirements.txt`: Зависимости проекта.
- `README.md`: Описание проекта.

## Установка

1. Клонируйте репозиторий.
2. Перейдите в директорию проекта.
3. Установите зависимости:

    ```bash
    pip install -r requirements.txt
    ```

## Запуск

1. Убедитесь, что данные находятся в директории `data/`.
2. Запустите все ячейки последовательно в `cryptonite.ipynb`:


## Результаты

Результаты сабмишна будут сохранены в `submission_trainer.csv`.