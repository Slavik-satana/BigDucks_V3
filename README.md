# Emotion Classification
Решение от команды 40 (БигДаки) для хакатона MFTIDS_2 x URFUML

## Содержание

1. [Состав команды и роли](#состав-команды-и-роли)
2. [Актуальное состояние проекта](#актуальное-состояние-проекта)
3. [Используемые методы](#используемые-методы)
    * [Предобработка данных](#предобработка-данных)
    * [Архитектура модели](#архитектура-модели)
4. [Планы доработки](#планы-доработки)
5. [Структура Проекта](#структура-проекта)
6. [Установка](#установка)
7. [Запуск](#запуск)
8. [Результаты](#результаты)

## Состав команды и роли

- Самаковский Вячеслав: Тим-лид, расширение датасета
- Казиев Владислав: Построение классификатора, расширение датасета
- Гришин Егор: Построение классификатора, расширение датасета
- Алексеев Арслан: Расширение датасета, визуализация результатов

## Актуальное состояние проекта
В настоящий момент удалось набрать score `0.58766` на лидерборде в kaggle

- Протестированные модели:
  - **ru-en-RoSBERTa** (В настоящий момент показала лучший езультат)
  - xlm-roberta-base
  - rugpt3small_based_on_gpt2
  - ruRoberta-large
  - ru-t5-large

## Используемые методы

### Предобработка данных

- На данном этапе предобработка данных включает базовые шаги [пердобработки](#предобработка-и-постобработка).

Планируем исследовать влияние очистка данных и исправления ошибок с помощью `ai-forever/sage`.

## Архитектура модели


### Предобученная языковая модель (Transformer Encoder):
В качестве основы берем предобученную модель `ru-en-RoSBERTa`. Модель преобразует входной текст в эмбединг. Используем стандартная токенизация и механизм внимания.

### Классификация:
Задача решается как Multilabel классификация.
Лосс-функция — `BCEWithLogitsLoss`, которая хорошо подходит для Multilabel задач.

### Подбор порога:
Мы перебираем серию порогов для максимизации F1, что повышает качество распознавания.

### Предобработка и постобработка:
- Предварительная очистка текста от `неалфавитных символов` и `лишних пробелов`.
- Токенизация до фиксированной длины (padding/truncation).
- Кодирование в one-hot формат.
- Получив предсказания на `valid` и `test` — примененяем `оптимальный Threshold` для улучшения качества.

## Планы доработки

В ближайших планах команды:

1. Проверка влияния Stratified K Fold Cross Validation:
   - Для повышения стабильности и обобщающей способности модели.

2. Тестирование различных моделей из лидерборда на русском языке:
   - Исследование моделей [лидерборда HuggingFace](https://huggingface.co/spaces/mteb/leaderboard)  на предмет их эффективности для нашей задачи.

3. Дальнейшее расширение датасета:
   - За счёт интеграции других релевантных датасетов, например, [ru-go-emotions](https://huggingface.co/datasets/seara/ru_go_emotions).

4. Оптимизация предобработки данных:
   - Внедрение методов очистки данных от шума и ошибок для улучшения качества обучения.


## Структура Проекта

- `data/`: Исходные данные.
- `src/`: Исходный код.
- `outputs/`: Результаты работы, включая сабмишны и логи.
- `requirements.txt`: Зависимости проекта.
- `README.md`: Описание проекта.

## Установка

1. Клонируйте репозиторий.
2. Перейдите в директорию проекта.
3. Установите зависимости:

    ```bash
    pip install -r requirements.txt
    ```

## Запуск

1. Убедитесь, что данные находятся в директории `data/`.
2. Запустите основной скрипт:

    ```bash
    python src/main.py
    ```

## Результаты

Результаты сабмишна будут сохранены в `outputs/submission.csv`.